{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hacettepe University Department of Computer Engineering\n",
    "# BBM 409 - Fall 2019\n",
    "# Second Assignment\n",
    "## Name: Mert Çökelek\n",
    "## ID: 21727082\n",
    "\n",
    "#####################################################################################################\n",
    "# REPORT AND CODE\n",
    "\n",
    "# Part I: Theory Questions\n",
    "## MLE\n",
    "### Question 1.\n",
    "Since there are **'m'** instances and they are uniformly distritubed in range **'-w, +w'**, for any given value in this space, has likelood: **1 / 2w**\n",
    "\n",
    "#### 1.1\n",
    "* **F(W) = (1/2W)^m**\n",
    "$$F ( W\\ ) = \\prod _ { i = 1 } ^ { m } P \\left( X _ { i } | \\ W\\right) = \\left( \\frac { 1 \\ } { 2W } \\right) ^ { m } $$\n",
    "\n",
    "\n",
    "#### 1.2\n",
    "* MLE argmax_W(P(x1, x2....xm | W) = argmaxTheta(1/W^m).\n",
    "* Because there are m instances with equal probability. All MLE are equal \n",
    "\n",
    "\n",
    "* So, **MLE = max{x1, x2, .... xm} = x_max.**\n",
    "\n",
    "#### 1.3\n",
    "* Dataset should be linearly non-seperable to not being performed well. So, it can be {(xi, yi)} = {(1, 0), (2, 1), (3, 0) ,(4, 0), (5, 1)}.\n",
    "\n",
    "\n",
    "### Question 2. \n",
    "* **True**. It looks mean and variance for all the occurences in dataset.\n",
    "* **False**. Because Bayesian approach can work well with small datasets, when the number of features are large.\n",
    "\n",
    "## Naive Bayes\n",
    "### Question 1.\n",
    "#### 1.1\n",
    "* **Answer: 1/2**\n",
    "* P(C = 1|x = 1, y = 1, z = 0) = P(C = 1, x = 1, z = 1, C = 0)/P(x = 1, y = 1, z = 0)\n",
    "* =P(C = 1) * P(x = 1|C = 1) * P(y = 1|C = 1) * P (z = 0|C = 1)/ P(x = 1, y = 1, z = 0, C = 1) + P(x = 1, y = 1, z = 0, C = 0)\n",
    "* = (1/2 * 1/2 * 1/4 * 1) / 1/8\n",
    "* = 1/16 / 1/8\n",
    "* = 1/2\n",
    "\n",
    "\n",
    "\n",
    "#### 1.2\n",
    "* **Answer: 1/2**\n",
    "* P(C = 0|x = 1, y = 1) = P(C = 0, x = 1 , y = 1)/P(x = 1 ∧ y = 1)\n",
    "* = P(C = 0) * P(x = 1|C = 0) * P(y = 1|C = 0)/ P(x = 1, y = 1, C = 1) + P(x = 1, y = 1, C = 0).\n",
    "* = P(C = 0) * P(X = 1)\n",
    "* P(C = 0|x = 1, y = 1) = (a) / (a+b)\n",
    "* a = P(x=1, y=1|C=1) * P(C=1)\n",
    "* b = P(x=1, y=1|C=0) * P(C=0)\n",
    "* a = 1/2 * 1/2\n",
    "* b = 1/2 * 1/2\n",
    "\n",
    "\n",
    "\n",
    "#### 1.3\n",
    "* **Answer: 0**\n",
    "* P(C = 1|x = 1, y = 1, c = 0). **There doesn't exist such an entry in the table, so joint naive bayes is equal to 0**\n",
    "\n",
    "#### 1.4\n",
    "* **Answer: 1/2**\n",
    "* **P(C = 0|x = 1, y = 1)** = **count**(C = 0, a = 1, y = 1) / **count**(x = 1, y = 1)** = 1/2.\n",
    "\n",
    "### Question 2.\n",
    "\n",
    "#### 2.1\n",
    "* **Answer: Not enough information**.\n",
    "* We need also at least P(C)\n",
    "\n",
    "#### 2.2\n",
    "\n",
    "* **Answer: Not enough information.**\n",
    "* We need also P(C)\n",
    "\n",
    "#### 2.3\n",
    "\n",
    "* **Answer: 2/3.**\n",
    "* P(B) = 1 => P(C|A, B) = P(C|A). So, P(C|A, B) = P(C, A) / P(A) = 0.2 / 0.3 = 2/3.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part II: Detection of Fake News\n",
    "\n",
    "## INTRODUCTION\n",
    "To classify if a news text is real or it is fake, Naive Bayes Classifier is a successful and efficient, commonly used classifier.\n",
    "Naive Bayes Classifier is mostly used for text classification.\n",
    "\n",
    "## Naïve Bayes Classifier\n",
    "* The train data must have a pre-given label. (In our case, 0 for Real News; 1 for Fake News.)\n",
    "* Given a dataset as text-label pairs, Naive Bayes first groups the text according to their labels.\n",
    "* For for every **label(class)**, it assumes that every single word in that text are **independent**. \n",
    "* After grouping texts, it calculates probabilities for every single word in that text.\n",
    "* It uses a **'Bag of Words'** model in which the order of the words are insignificant.\n",
    "* These probabilities correspond to the conditional probabilities of a word, given the class label.\n",
    "* The probability(likelihood) of a word in BoW is calculated with the formula:$$   P(w|c) = \\frac{n(c) + 1}{count(c)+|V|}$$\n",
    "\n",
    "\n",
    "* Here, the +1 comes from the idea **'Laplace Smoothing'**.  If a word does not occur in that class, it gives that word a small probability, rather than pure zero."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Data:\n",
    "\n",
    "* First, taking the .csv files as pandas dataframe\n",
    "* Removing **NaN** values from **'text'** and **'title'** columns to prevent the noise in data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv('fake_news_train.csv') \n",
    "data['title'] = data['title'].fillna(value='') # Replace NaNs with empty string.\n",
    "data = data[pd.notnull(data['text'])]          # Remove NaNs from 'text' column in dataset.\n",
    "data = data[data['text'].map(len) > 2]         # Remove empty strings from texts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Printing the dataframe, to see if the data is taken correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>FLYNN: Hillary Clinton, Big Woman on Campus - ...</td>\n",
       "      <td>Daniel J. Flynn</td>\n",
       "      <td>Ever get the feeling your life circles the rou...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>15 Civilians Killed In Single US Airstrike Hav...</td>\n",
       "      <td>Jessica Purkiss</td>\n",
       "      <td>Videos 15 Civilians Killed In Single US Airstr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>Jackie Mason: Hollywood Would Love Trump if He...</td>\n",
       "      <td>Daniel Nussbaum</td>\n",
       "      <td>In these trying times, Jackie Mason is the Voi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>Life: Life Of Luxury: Elton John’s 6 Favorite ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ever wonder how Britain’s most iconic pop pian...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Benoît Hamon Wins French Socialist Party’s Pre...</td>\n",
       "      <td>Alissa J. Rubin</td>\n",
       "      <td>PARIS  —   France chose an idealistic, traditi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16635</td>\n",
       "      <td>20795</td>\n",
       "      <td>Rapper T.I.: Trump a ’Poster Child For White S...</td>\n",
       "      <td>Jerome Hudson</td>\n",
       "      <td>Rapper T. I. unloaded on black celebrities who...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16636</td>\n",
       "      <td>20796</td>\n",
       "      <td>N.F.L. Playoffs: Schedule, Matchups and Odds -...</td>\n",
       "      <td>Benjamin Hoffman</td>\n",
       "      <td>When the Green Bay Packers lost to the Washing...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16637</td>\n",
       "      <td>20797</td>\n",
       "      <td>Macy’s Is Said to Receive Takeover Approach by...</td>\n",
       "      <td>Michael J. de la Merced and Rachel Abrams</td>\n",
       "      <td>The Macy’s of today grew from the union of sev...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16638</td>\n",
       "      <td>20798</td>\n",
       "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
       "      <td>Alex Ansary</td>\n",
       "      <td>NATO, Russia To Hold Parallel Exercises In Bal...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16639</td>\n",
       "      <td>20799</td>\n",
       "      <td>What Keeps the F-35 Alive</td>\n",
       "      <td>David Swanson</td>\n",
       "      <td>David Swanson is an author, activist, journa...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16549 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                              title  \\\n",
       "0          1  FLYNN: Hillary Clinton, Big Woman on Campus - ...   \n",
       "1          3  15 Civilians Killed In Single US Airstrike Hav...   \n",
       "2          5  Jackie Mason: Hollywood Would Love Trump if He...   \n",
       "3          6  Life: Life Of Luxury: Elton John’s 6 Favorite ...   \n",
       "4          7  Benoît Hamon Wins French Socialist Party’s Pre...   \n",
       "...      ...                                                ...   \n",
       "16635  20795  Rapper T.I.: Trump a ’Poster Child For White S...   \n",
       "16636  20796  N.F.L. Playoffs: Schedule, Matchups and Odds -...   \n",
       "16637  20797  Macy’s Is Said to Receive Takeover Approach by...   \n",
       "16638  20798  NATO, Russia To Hold Parallel Exercises In Bal...   \n",
       "16639  20799                          What Keeps the F-35 Alive   \n",
       "\n",
       "                                          author  \\\n",
       "0                                Daniel J. Flynn   \n",
       "1                                Jessica Purkiss   \n",
       "2                                Daniel Nussbaum   \n",
       "3                                            NaN   \n",
       "4                                Alissa J. Rubin   \n",
       "...                                          ...   \n",
       "16635                              Jerome Hudson   \n",
       "16636                           Benjamin Hoffman   \n",
       "16637  Michael J. de la Merced and Rachel Abrams   \n",
       "16638                                Alex Ansary   \n",
       "16639                              David Swanson   \n",
       "\n",
       "                                                    text  label  \n",
       "0      Ever get the feeling your life circles the rou...      0  \n",
       "1      Videos 15 Civilians Killed In Single US Airstr...      1  \n",
       "2      In these trying times, Jackie Mason is the Voi...      0  \n",
       "3      Ever wonder how Britain’s most iconic pop pian...      1  \n",
       "4      PARIS  —   France chose an idealistic, traditi...      0  \n",
       "...                                                  ...    ...  \n",
       "16635  Rapper T. I. unloaded on black celebrities who...      0  \n",
       "16636  When the Green Bay Packers lost to the Washing...      0  \n",
       "16637  The Macy’s of today grew from the union of sev...      0  \n",
       "16638  NATO, Russia To Hold Parallel Exercises In Bal...      1  \n",
       "16639    David Swanson is an author, activist, journa...      1  \n",
       "\n",
       "[16549 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting data into train and test sets. \n",
    "* Kaggle input will be used as the validation set.\n",
    "* Sorting train data provides easy slicing of real and fake news.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train, Test = train_test_split(data, test_size=0.20)\n",
    "Train = Train.sort_values(by=['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Here are the helper functions, which will be used in Part1, Part2, Part3, Part4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 1 := Vectorize()\n",
    "* This function uses a vectorizer (CountVectorizer or TfidfVectorizer) and fits the train and test data into a common vector.\n",
    "* **train vector** is created by **'fit_transform()'** because the words in the test data will be compared according to this vector.\n",
    "* **test vector** is created by **'transform()'** because we need the indices of the words in test files to be the same as in the train file.\n",
    "* **rating_probs:** ratio of zero-label, one-label. Used for calculating **Priors**\n",
    "* **bow:** Bag of Words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "def Vectorize(vectorizer, feature, train, test, stop_words=None, ngram = 1):\n",
    "    if vectorizer == 'CountVectorizer':\n",
    "        if stop_words==None:\n",
    "            vector = CountVectorizer(ngram_range=(ngram, ngram))\n",
    "        else:\n",
    "            vector = CountVectorizer(analyzer='word', stop_words=stop_words, ngram_range=(ngram, ngram))\n",
    "            \n",
    "    elif vectorizer == 'TfidfVectorizer':\n",
    "        if stop_words==None:\n",
    "            vector = TfidfVectorizer(ngram_range=(ngram, ngram))\n",
    "        else:\n",
    "            vector = TfidfVectorizer(analyzer='word', stop_words=stop_words, ngram_range=(ngram, ngram))\n",
    "\n",
    "    train_vector = vector.fit_transform(train[feature])  \n",
    "    test_vector = vector.transform(test[feature].apply(lambda x: np.str_(x)))  \n",
    "    \n",
    "    rating_probs = train.groupby('label').size().div(len(train))\n",
    "    P_real = rating_probs[0]\n",
    "    P_fake = rating_probs[1]\n",
    "    \n",
    "    bow = vector.get_feature_names()\n",
    "    \n",
    "    train_ = [train_vector, P_real, P_fake, bow]\n",
    "    test_ = [test_vector]\n",
    "    return train_, test_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 2 := naive_bayes()\n",
    "* This function uses the **Vectorize()** functioni which was created in the previous cell.\n",
    "* **The parameters are:**\n",
    "* **1-feature:** feature stands for either 'title' or 'text'. **Title** will be used in **Part1** of this assignment, to make classification according to the title of the news; and see if it is feasible to use only Titles.\n",
    "* **2-train_data, test_data:** The pandas dataframes, which were created by **Train_test_split()** method.\n",
    "* **real_size:** The number of real news in the training set. Used for slicing the dataset.\n",
    "* **analyzer, stop_words:** None or 'English', to see their effects on accuracy.\n",
    "* **ngram:** Can be 1 or 2. \n",
    "\n",
    "### Implementing Naive Bayes:\n",
    "* **PARAMETERS:** train_data and test_data: the datasets. real_size: number of real news in train data.\n",
    "* **stop_words:** stopwords are the common and insignificant-for-fake-detections, so it maybe useful to use them.\n",
    "* **ngramrange:** Determines how the words from BoW will be taken. 1-1, or 2-2.\n",
    "* **THESE PARAMETERS ARE VARIABLE, SO EVERY POSSIBLE COMBINATION WILL BE CALCULATED TO PICK THE MOST ACCURATE ONE**\n",
    "\n",
    "#### Inside the function:\n",
    "* **news:** number of test text\n",
    "* **real, fake:** in the train data, real news are labeled via 0, fake news are labeled via 1.\n",
    "* **P_words_given_real/fake:** The indepentent probabilities of the words in BoW, for real and fake news, seperately.\n",
    "* **P_Real, P_Fake:** The class priors. Required for prediction.\n",
    "* **predictions:** an array of 0-1s, corresponding to every single text in test file.\n",
    "* In for loop, i corresponds to i'th text in test. \n",
    "* **preal, pfake:** are calculated by log probabilities of the total likelihoods of the words in test words.\n",
    "* This final operation is complicated. In a brute-force solution, 2 for loops required(1 for text number, 1 for word in that text). **In my solution**, the words obtained from i'th text in test data are gathered from the train's real and fake parts, with a matrix.\n",
    "* The matrix calculation provides a fast and simple way to calculate total log probabilities of the words in text.\n",
    "* With one-line matrix calculation, I can calculate the log probabilities of the words.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Real_news_number = Train[Train['label'] == 0].shape[0]\n",
    "\n",
    "def naive_bayes(vectorizer, feature, train_data, test_data, real_size, stop_words=None, ngram = 1 ):\n",
    "    train, test = Vectorize(vectorizer, feature, train_data, test_data, stop_words=stop_words, ngram=ngram)\n",
    "    Train_Vector, P_Real, P_Fake, Bow_Train = train[0], train[1], train[2], train[3]\n",
    "    Test_Vector = test[0]\n",
    "    \n",
    "    bowLen = len(Bow_Train)    \n",
    "    news = Test_Vector.shape[0]\n",
    "    \n",
    "    \n",
    "    real = Train_Vector[:real_size]\n",
    "    fake = Train_Vector[real_size:]\n",
    "    \n",
    "    P_words_given_real = np.log10((real.sum(axis=0)+1) / (real.sum() + bowLen))\n",
    "    P_words_given_fake = np.log10((fake.sum(axis=0)+1) / (fake.sum() + bowLen))\n",
    "    \n",
    "    P_Real = np.log10(P_Real)\n",
    "    P_Fake = np.log10(P_Fake)\n",
    "    \n",
    "    predictions = []\n",
    "    for i in range(news):\n",
    "        preal, pfake = P_Real, P_Fake # Class priors.\n",
    "        \n",
    "        test_text = Test_Vector[i] # i'th text in test news.\n",
    "        \n",
    "        cols = test_text.nonzero()[1] # the existing words in text are taken. If a word does not exist, it is unnecessary for our calculation.\n",
    "        \n",
    "        preal += test_text[0,cols].multiply(P_words_given_real[0, cols]).sum() # Existing words are taken from real news.\n",
    "        pfake += test_text[0,cols].multiply(P_words_given_fake[0, cols]).sum() # Existing words are taken from fake news.\n",
    "         \n",
    "        if(preal >= pfake):\n",
    "            predictions.append(0)\n",
    "        else:\n",
    "            predictions.append(1)\n",
    "    return predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function 3 := accuracy()\n",
    "* This is a simple function that takes the **prediction matrix**(which was created by naive_bayes(), and **compares** its differences between the **Correct Labels**, to print the success rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(predictions, actual):\n",
    "    err = 0\n",
    "    Len = len(predictions)\n",
    "    for i in range(Len):\n",
    "        err += np.abs(predictions[i] - actual[i])\n",
    "        \n",
    "    err = err / Len\n",
    "    return((1-err) *100)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Understanding the Data\n",
    "* In this part, Naive Bayes will be applied to headlines of the news. To check if it is feasible to classify by titles.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_by_headlines_1 = naive_bayes('CountVectorizer','title', Train, Test, Real_news_number, ngram=1)\n",
    "prediction_by_headlines_2 = naive_bayes('CountVectorizer','title', Train, Test, Real_news_number, ngram=2)\n",
    "prediction_by_headlines_3 = naive_bayes('CountVectorizer','title', Train, Test, Real_news_number, ngram=3)\n",
    "prediction_by_headlines_4 = naive_bayes('CountVectorizer','title', Train, Test, Real_news_number, ngram=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy by headlines, 1-gram: 87.91540785498489\n",
      "Accuracy by headlines, 2-gram: 80.60422960725076\n",
      "Accuracy by headlines, 3-gram: 67.0392749244713\n",
      "Accuracy by headlines, 4-gram: 58.42900302114804\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy by headlines, 1-gram:\", accuracy(prediction_by_headlines_1, Test['label'].values))\n",
    "print(\"Accuracy by headlines, 2-gram:\", accuracy(prediction_by_headlines_2, Test['label'].values))\n",
    "print(\"Accuracy by headlines, 3-gram:\", accuracy(prediction_by_headlines_3, Test['label'].values))\n",
    "print(\"Accuracy by headlines, 4-gram:\", accuracy(prediction_by_headlines_4, Test['label'].values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* As an average of 10 random runs, the average accuracy of classifying **only by titles** is **87-88%**.\n",
    "* **Using Unigram** is ~88%, where **Using Bigram** is ~80%.\n",
    "* Incrementing the n-gram, accuracy decreased.\n",
    "* This may be because the titles are already short, using double-triple word pairs may result noise and uncertainity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer\n",
    "\n",
    "def PART_1_get_3_words(real_or_fake, train):\n",
    "    if real_or_fake == 'real':\n",
    "        news = train[train['label'] == 0]\n",
    "    else:\n",
    "        news = train[train['label'] == 1]\n",
    "    \n",
    "    cv = CountVectorizer(analyzer='word', stop_words='english')\n",
    "    word_count_vector = cv.fit_transform(news['title'])\n",
    "    tfidf_transformer = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "    tfidf_transformer.fit(word_count_vector)\n",
    "    df = pd.DataFrame(tfidf_transformer.idf_, index=cv.get_feature_names(), columns=['IDF Weights'])\n",
    "\n",
    "    df.sort_values(by=['IDF Weights'], ascending=True, inplace=True)\n",
    "\n",
    "    return df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>new</td>\n",
       "      <td>1.493855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>times</td>\n",
       "      <td>1.505349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>york</td>\n",
       "      <td>1.507344</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IDF Weights\n",
       "new       1.493855\n",
       "times     1.505349\n",
       "york      1.507344"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_real_3_words = PART_1_get_3_words('real', data)\n",
    "title_real_3_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These are the **top 3 words** most strongly predicting the news is real."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IDF Weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>trump</td>\n",
       "      <td>2.995065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>hillary</td>\n",
       "      <td>3.315418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>clinton</td>\n",
       "      <td>3.470799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         IDF Weights\n",
       "trump       2.995065\n",
       "hillary     3.315418\n",
       "clinton     3.470799"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_fake_3_words = PART_1_get_3_words('fake', data)\n",
    "title_fake_3_words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These are the **top 3 words** most strongly predicting the news is fake.\n",
    "* Using these words for train dataset has an outcome with **88%** accuracy.\n",
    "* **So, it may be feasible for predicting news by headlines**\n",
    "* But, the accuracy can be better.\n",
    "* Let's try Naive Bayes solution for Texts in news."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Implementing Naive Bayes\n",
    "* In first part, classifying by 'Titles' was not successful enough.\n",
    "* In this part, we are going to use the **naive_bayes()** function **for the test data.**\n",
    "* I encountered the **unseen words in test data** by simply giving them **0 probability**, and after that with **Laplace Smoothing**, they took a small probability.\n",
    "### The next cell can take 2-3 minutes to run, because 'Bigram' Naive Bayes takes a long time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Predictions = dict()\n",
    "Predictions['Using Text, 1-gram, no stop_words'] = naive_bayes('CountVectorizer','text', Train, Test, Real_news_number)\n",
    "Predictions['Using Text, 2-gram, no stop_words'] = naive_bayes('CountVectorizer','text', Train, Test, Real_news_number, ngram=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Text, 1-gram, no stop_words \t 90.18126888217523\n",
      "Using Text, 2-gram, no stop_words \t 91.45015105740183\n"
     ]
    }
   ],
   "source": [
    "for key, value in Predictions.items():\n",
    "    print(key, '\\t' ,accuracy(value, Test['label'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accuracy of the predictions are calculated.\n",
    "* The **accuracy** is now about **90-92%**.\n",
    "* **There is** an **improvement** since using headlines, but **still can be better**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " * Using **Bigram**, the accuracy increased about 1.5%. \n",
    " * This is because, there can be some word-pairs which have a different meaning than the singular ones. \n",
    " * When **adjacent single words** are combined together, their meaning and the news' reality prediction changes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: \n",
    "### 3a, 3b: Analyzing the effects of words on prediction:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "def print_10_words(train):\n",
    "    \n",
    "    real_df = pd.DataFrame(train[train['label'] == 0])\n",
    "    fake_df = train.drop(real_df.index)\n",
    "\n",
    "    # Bag of Words for Real news. With their frequencies, helper = TfidfTransformer\n",
    "    cv1 = CountVectorizer()\n",
    "    word_count_vector1 = cv1.fit_transform(real_df['text'])\n",
    "    tfidf_transformer1 = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "    tfidf_transformer1.fit(word_count_vector1)\n",
    "    bow1 = cv1.get_feature_names()\n",
    "    \n",
    "    # Bag of Words for Fake news. With their frequencies, helper = TfidfTransformer\n",
    "\n",
    "    cv2 = CountVectorizer()\n",
    "    word_count_vector2 = cv2.fit_transform(fake_df['text'])\n",
    "    tfidf_transformer2 = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "    tfidf_transformer2.fit(word_count_vector2)\n",
    "    bow2 = cv2.get_feature_names()\n",
    "\n",
    "    \n",
    "#     real_bow = set(bow1) - set(bow2) # Remove the words in Fake news, from the Real news.\n",
    "#     fake_bow = set(bow2) - set(bow1) # Remove the words in Real news, from the Fake news.\n",
    "\n",
    "    # Create DataFrames for good visual.\n",
    "    \n",
    "    real = pd.DataFrame(list(zip(bow1, tfidf_transformer1.idf_)),columns=['Word', 'IDF-Weight'])\n",
    "    fake = pd.DataFrame(list(zip(bow2, tfidf_transformer2.idf_)), columns=['Word', 'IDF-Weight'])\n",
    "    \n",
    "    real_ = real.loc[real['Word'].isin(bow1)]\n",
    "    fake_ = fake.loc[fake['Word'].isin(bow2)]\n",
    "\n",
    "    real_prs = real_.nsmallest(10, 'IDF-Weight') # Presence most strongly predicts real news\n",
    "    fake_prs = fake_.nsmallest(10, 'IDF-Weight') # Presence most strongly predicts fake news\n",
    "    real_abs= real_.nlargest(10, 'IDF-Weight')   # Absence most strongly predicts real news\n",
    "    fake_abs = fake_.nlargest(10, 'IDF-Weight')  # Absence most strongly predicts fake news\n",
    "    \n",
    "    return real_prs, real_abs, fake_prs, fake_abs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Real_presence, Real_absence, Fake_presence, Fake_absence = print_10_words(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>IDF-Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>79129</td>\n",
       "      <td>the</td>\n",
       "      <td>1.001324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79998</td>\n",
       "      <td>to</td>\n",
       "      <td>1.006394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55956</td>\n",
       "      <td>of</td>\n",
       "      <td>1.007968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4667</td>\n",
       "      <td>and</td>\n",
       "      <td>1.009181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38802</td>\n",
       "      <td>in</td>\n",
       "      <td>1.017345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56295</td>\n",
       "      <td>on</td>\n",
       "      <td>1.020041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79110</td>\n",
       "      <td>that</td>\n",
       "      <td>1.033255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30090</td>\n",
       "      <td>for</td>\n",
       "      <td>1.051825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40546</td>\n",
       "      <td>is</td>\n",
       "      <td>1.065084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86970</td>\n",
       "      <td>with</td>\n",
       "      <td>1.085177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  IDF-Weight\n",
       "79129   the    1.001324\n",
       "79998    to    1.006394\n",
       "55956    of    1.007968\n",
       "4667    and    1.009181\n",
       "38802    in    1.017345\n",
       "56295    on    1.020041\n",
       "79110  that    1.033255\n",
       "30090   for    1.051825\n",
       "40546    is    1.065084\n",
       "86970  with    1.085177"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Real_presence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 words whose presence most strongly predicts that the news is real.\n",
    "* **Low weight** means that word **occurs more**, in that label.\n",
    "* These are some **English stop words** and they can both appear in **real news/fake news**. \n",
    "* Since they can appear on both labels, **occurence** will not change our program's **accuracy on real news.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>IDF-Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000</td>\n",
       "      <td>9.332789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001</td>\n",
       "      <td>9.332789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>000s</td>\n",
       "      <td>9.332789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0024</td>\n",
       "      <td>9.332789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>003</td>\n",
       "      <td>9.332789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>00pm</td>\n",
       "      <td>9.332789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0102</td>\n",
       "      <td>9.332789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>012</td>\n",
       "      <td>9.332789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0134</td>\n",
       "      <td>9.332789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>015</td>\n",
       "      <td>9.332789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Word  IDF-Weight\n",
       "2   0000    9.332789\n",
       "3   0001    9.332789\n",
       "4   000s    9.332789\n",
       "8   0024    9.332789\n",
       "9    003    9.332789\n",
       "14  00pm    9.332789\n",
       "17  0102    9.332789\n",
       "18   012    9.332789\n",
       "19  0134    9.332789\n",
       "20   015    9.332789"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Real_absence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top 10 words whose absence most strongly predicts that the news is real:\n",
    "* **High weight** means that word **occurs least**. \n",
    "* So it is logical that **these words' absence** will **increase** our program's **accuracy on real news.**\n",
    "* We can see that these words are **meaningless words**. So they do **nothing but confusing** the datasets.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>IDF-Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>87865</td>\n",
       "      <td>the</td>\n",
       "      <td>1.091892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88767</td>\n",
       "      <td>to</td>\n",
       "      <td>1.123950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62699</td>\n",
       "      <td>of</td>\n",
       "      <td>1.133202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6342</td>\n",
       "      <td>and</td>\n",
       "      <td>1.141561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44526</td>\n",
       "      <td>in</td>\n",
       "      <td>1.154373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46934</td>\n",
       "      <td>is</td>\n",
       "      <td>1.222082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87847</td>\n",
       "      <td>that</td>\n",
       "      <td>1.227555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63164</td>\n",
       "      <td>on</td>\n",
       "      <td>1.228623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35085</td>\n",
       "      <td>for</td>\n",
       "      <td>1.243229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47111</td>\n",
       "      <td>it</td>\n",
       "      <td>1.308005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Word  IDF-Weight\n",
       "87865   the    1.091892\n",
       "88767    to    1.123950\n",
       "62699    of    1.133202\n",
       "6342    and    1.141561\n",
       "44526    in    1.154373\n",
       "46934    is    1.222082\n",
       "87847  that    1.227555\n",
       "63164    on    1.228623\n",
       "35085   for    1.243229\n",
       "47111    it    1.308005"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fake_presence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 words whose presencee most strongly predicts that the news is fake.\n",
    "* **Low weight** means that word **occurs most** in that label.** \n",
    "* These are some **English stop words** and they can both appear in **real news/fake news**. \n",
    "* Since they can appear on both labels, **occurence** will not change our program's **accuracy on real news.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>IDF-Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0000</td>\n",
       "      <td>9.323001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001</td>\n",
       "      <td>9.323001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>00012</td>\n",
       "      <td>9.323001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0002</td>\n",
       "      <td>9.323001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>000202</td>\n",
       "      <td>9.323001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>000205</td>\n",
       "      <td>9.323001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>000billion</td>\n",
       "      <td>9.323001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>000emails</td>\n",
       "      <td>9.323001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>000ft</td>\n",
       "      <td>9.323001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>000k</td>\n",
       "      <td>9.323001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Word  IDF-Weight\n",
       "2         0000    9.323001\n",
       "3         0001    9.323001\n",
       "4        00012    9.323001\n",
       "5         0002    9.323001\n",
       "6       000202    9.323001\n",
       "7       000205    9.323001\n",
       "8   000billion    9.323001\n",
       "9    000emails    9.323001\n",
       "10       000ft    9.323001\n",
       "11        000k    9.323001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fake_absence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 words whose absence most strongly predicts that the news is fake.\n",
    "* We can see that all of these words are **meaningless words**. \n",
    "* **High weight** means that word **occurs least**. \n",
    "* So it is logical that these words' **absence** will **increase** our program's **accuracy on fake news.**\n",
    "* They do **nothing but confusing** the program. **They are meaningless.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "def print_10_words_without_stopwords(train):\n",
    "    \n",
    "    real_df = pd.DataFrame(train[train['label'] == 0])\n",
    "    fake_df = pd.DataFrame(train[train['label'] == 1])\n",
    "\n",
    "    # Bag of Words for Real news. With their frequencies, helper = TfidfTransformer\n",
    "    cv1 = CountVectorizer()\n",
    "    word_count_vector1 = cv1.fit_transform(real_df['text'])\n",
    "    tfidf_transformer1 = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "    tfidf_transformer1.fit(word_count_vector1)\n",
    "    bow1 = cv1.get_feature_names()\n",
    "    \n",
    "    # Bag of Words for Fake news. With their frequencies, helper = TfidfTransformer\n",
    "\n",
    "    cv2 = CountVectorizer()\n",
    "    word_count_vector2 = cv2.fit_transform(fake_df['text'])\n",
    "    tfidf_transformer2 = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
    "    tfidf_transformer2.fit(word_count_vector2)\n",
    "    bow2 = cv2.get_feature_names()\n",
    "\n",
    "    \n",
    "    real_bow = set(bow1) - set(bow2) # Remove the words in Fake news, from the Real news.\n",
    "    fake_bow = set(bow2) - set(bow1) # Remove the words in Real news, from the Fake news.\n",
    "\n",
    "    # Create DataFrames for good visual.\n",
    "    \n",
    "    real = pd.DataFrame(list(zip(bow1, tfidf_transformer1.idf_)),columns=['Word', 'IDF-Weight'])\n",
    "    fake = pd.DataFrame(list(zip(bow2, tfidf_transformer2.idf_)), columns=['Word', 'IDF-Weight'])\n",
    "    \n",
    "    real_ = real.loc[real['Word'].isin(real_bow)]\n",
    "    fake_ = fake.loc[fake['Word'].isin(fake_bow)]\n",
    "\n",
    "    real_nonstop = real_.nsmallest(10, 'IDF-Weight') # Presence most strongly predicts real news\n",
    "    fake_nonstop = fake_.nsmallest(10, 'IDF-Weight') # Presence most strongly predicts fake news\n",
    " \n",
    "    return real_nonstop, fake_nonstop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3c: Analyzing the effects of stopwords:\n",
    "* **Stopwords** can and will occur in almost all of the texts, **regardless it is real or fake.**\n",
    "\n",
    "* So **removing** them can **reduce noise** and **increase speed.**\n",
    "\n",
    "#### In the next part (Part 4), we will see the effects of using stopwords, TF-IDF, different n-gram values.\n",
    "\n",
    "### The next cell contains 8 different combinations of the Hyperparameters.\n",
    "### (Naive Bayes function is called 8-times, with different parameters)\n",
    "### So the running can take about 10 minutes.\n",
    "### If you don't run, there is a sample output of the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Real_nonstop, Fake_nonstop = print_10_words_without_stopwords(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>IDF-Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>57845</td>\n",
       "      <td>pamkeynen</td>\n",
       "      <td>4.784190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1893</td>\n",
       "      <td>_____</td>\n",
       "      <td>4.872645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79774</td>\n",
       "      <td>tillerson</td>\n",
       "      <td>5.128097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41406</td>\n",
       "      <td>jeromeehudson</td>\n",
       "      <td>5.135588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37820</td>\n",
       "      <td>huston</td>\n",
       "      <td>5.325456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33225</td>\n",
       "      <td>gorsuch</td>\n",
       "      <td>5.353108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38258</td>\n",
       "      <td>igcolonel</td>\n",
       "      <td>5.362498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85618</td>\n",
       "      <td>warnerthuston</td>\n",
       "      <td>5.362498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24727</td>\n",
       "      <td>dznussbaum</td>\n",
       "      <td>5.410816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34958</td>\n",
       "      <td>hanchett</td>\n",
       "      <td>5.493337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Word  IDF-Weight\n",
       "57845      pamkeynen    4.784190\n",
       "1893           _____    4.872645\n",
       "79774      tillerson    5.128097\n",
       "41406  jeromeehudson    5.135588\n",
       "37820         huston    5.325456\n",
       "33225        gorsuch    5.353108\n",
       "38258      igcolonel    5.362498\n",
       "85618  warnerthuston    5.362498\n",
       "24727     dznussbaum    5.410816\n",
       "34958       hanchett    5.493337"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Real_nonstop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **These are the top 10 non-stop words, predicting real news most strongly.**\n",
    "* Low weight means higher occurence in that label.\n",
    "* And obviously these are possible **unsuspicious words** for a real news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>IDF-Weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>42985</td>\n",
       "      <td>http</td>\n",
       "      <td>3.954692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59163</td>\n",
       "      <td>multi</td>\n",
       "      <td>4.934744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42984</td>\n",
       "      <td>html</td>\n",
       "      <td>5.110874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116385</td>\n",
       "      <td>что</td>\n",
       "      <td>5.148614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109500</td>\n",
       "      <td>по</td>\n",
       "      <td>5.164118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107313</td>\n",
       "      <td>не</td>\n",
       "      <td>5.220358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80062</td>\n",
       "      <td>sheeple</td>\n",
       "      <td>5.237025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105021</td>\n",
       "      <td>как</td>\n",
       "      <td>5.262558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104455</td>\n",
       "      <td>из</td>\n",
       "      <td>5.371758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103808</td>\n",
       "      <td>за</td>\n",
       "      <td>5.410978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Word  IDF-Weight\n",
       "42985      http    3.954692\n",
       "59163     multi    4.934744\n",
       "42984      html    5.110874\n",
       "116385      что    5.148614\n",
       "109500       по    5.164118\n",
       "107313       не    5.220358\n",
       "80062   sheeple    5.237025\n",
       "105021      как    5.262558\n",
       "104455       из    5.371758\n",
       "103808       за    5.410978"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fake_nonstop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **These are the top 10 non-stop words, predicting the fake news most strongly.**\n",
    "* Low weight means higher occurence for that label.\n",
    "* We see some **Links, such as 'http, html'** and some foreign words.\n",
    "* Also, those Russian words are **Russian Stopwords**, so they can also be ignored from the dataset.\n",
    "* These are obviously **suspicious words for a news**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predictions = dict()\n",
    "Predictions['CountVectorizer, 1-gram, with stop_words'] = naive_bayes('CountVectorizer', 'text', Train, Test, Real_news_number)\n",
    "Predictions['CountVectorizer, 2-gram, with stop_words'] = naive_bayes('CountVectorizer','text', Train, Test, Real_news_number, ngram=2)\n",
    "Predictions['CountVectorizer, 1-gram, no stop_words'] = naive_bayes('CountVectorizer','text', Train, Test, Real_news_number, stop_words='english')\n",
    "Predictions['CountVectorizer, 2-gram, no stop_words'] = naive_bayes('CountVectorizer','text', Train, Test, Real_news_number, ngram=2, stop_words='english')\n",
    "\n",
    "# Predictions['TF-IDF, 1-gram, with stop_words'] = naive_bayes('TfidfVectorizer', 'text', Train, Test, Real_news_number)\n",
    "# Predictions['TF-IDF, 2-gram, with stop_words'] = naive_bayes('TfidfVectorizer', 'text', Train, Test, Real_news_number, ngram=2)\n",
    "# Predictions['TF-IDF, 1-gram, no stop_words'] = naive_bayes('TfidfVectorizer', 'text', Train, Test, Real_news_number, stop_words='english')\n",
    "# Predictions['TF-IDF, 2-gram, no stop_words'] = naive_bayes('TfidfVectorizer', 'text', Train, Test, Real_news_number, ngram=2, stop_words='english')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4: Prediction / Accuracy"
   ]
  },
  {
   "attachments": {
    "as.PNG": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **This was the output when I ran this code on my PC.**\n",
    "* In the previous cell, **the last 4 lines** are **commented**. Because using **TF-IDF** in this large dataset took approximately 10 minutes.\n",
    "* **If you'd like to see the outputs anyway, there is a sample screenshot from one of my runs**.\n",
    "![as.PNG](attachment:as.PNG)\n",
    "### From the output, what we conclude are:\n",
    "* **Setting n-gram** range **to 2 incremented accuracy** by 1-7%.\n",
    "* This is **because** there are so many unique words in dataset and **combining them together increments** number of total features.\n",
    "* **The more feature numbers the better Naive Bayes works**, since it's fed from large amount of features.\n",
    "* **Removing StopWords** from the dataset **incremented the accuracy** by 5-10%.\n",
    "* This is **because**, these **stop words can occur** in **both real and fake news**. Using them and making predictions is not a good idea. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer, 1-gram, with stop_words \t 90.18126888217523\n",
      "CountVectorizer, 2-gram, with stop_words \t 91.45015105740183\n",
      "CountVectorizer, 1-gram, no stop_words \t 89.15407854984895\n",
      "CountVectorizer, 2-gram, no stop_words \t 92.62839879154079\n"
     ]
    }
   ],
   "source": [
    "for key, value in Predictions.items():\n",
    "    print(key , '\\t',accuracy(value, Test['label'].values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
